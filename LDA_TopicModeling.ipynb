{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA_TopicModeling.ipynb",
      "provenance": [],
      "mount_file_id": "1LhkfH4tc60903pbcoJfly-HbXkg-Lf2s",
      "authorship_tag": "ABX9TyOkq7RTVaiX+UWY+l8TavGn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dudwn98/iipl_topic_modeling/blob/main/LDA_TopicModeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN0N6eCwgTh8"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import re\n",
        "import konlpy"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbPJWLGnu6sH"
      },
      "source": [
        "def preprocessing(news):\n",
        "    #개행 제거\n",
        "    news = re.sub('\\\\\\\\n', '', news)\n",
        "    #이메일 제거\n",
        "    news = re.sub(r'\\b[\\w\\+]+@[\\w]+.[\\w]+.[\\w]+.[\\w]+\\b', ' ', news)\n",
        "    #특수문자, 자음 제거\n",
        "    news = re.sub(r'[^ㄱ-ㅣ가-힣A-Za-z0-9]',' ', news)\n",
        "    #중복 공백 제거\n",
        "    news = re.sub(' +', ' ', news)\n",
        "    return news"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HifA7tAwJjx"
      },
      "source": [
        "def remove_stopwords(text):\n",
        "    okt = konlpy.tag.Okt()\n",
        "    tokens = okt.nouns(text)\n",
        "\n",
        "    stops = ['기자', '뉴스', '경향', '뉴시스', '무단 배포', '금지', '무단',\n",
        "             '위해', '보기', '배포', '비롯', '통해', '통한', '마련', '다른',\n",
        "             '가지', '여개', '개', '또', '평']\n",
        "    meaningful_words = [w for w in tokens if not w in stops]\n",
        "    return ' '.join(meaningful_words)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYXPZ39u32Sh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f44deb0-862d-4307-8659-deb2aa01d875"
      },
      "source": [
        "path='/content/drive/MyDrive/크롤링 데이터/2018/2017서울포커스.csv'\n",
        "\n",
        "file = pd.read_csv(path, encoding='cp949')\n",
        "df = pd.DataFrame({'doc' : file.기사제목 + file.기사내용})\n",
        "\n",
        "df.loc[:, 'doc'] = df['doc'].apply(preprocessing)\n",
        "df.loc[:, 'doc'] = df['doc'].apply(remove_stopwords)\n",
        "print(df)\n",
        "## 텍스트 데이터를 단어 빈도수에 기반해 벡터화시키기\n",
        "# max_df = 토큰이 나타날 최대 문서 개수 -> 소수점이면 비중\n",
        "# max_features = corpus 중 빈도수가 가장 높은 순으로 해당 개수만큼만 뽑아냄\n",
        "# min_df = 토큰이 나타날 최소 문서 개수 -> 정수면 횟수\n",
        "# ngram_range = (min_n, max_n) 튜플, 단어장 생성에 사용할 토큰의 크기를 결정\n",
        "count_vect = CountVectorizer(max_df=0.95, max_features=1000,\n",
        "                            min_df=2, ngram_range=(1,1))\n",
        "# feature 리스케일링 해서 feature 평균이 0 분산이 1 되게 만들어줌\n",
        "#fit_transfrom은 train dataset에서만 사용\n",
        "ftr_vect = count_vect.fit_transform(df.doc)\n",
        "\n",
        "# LDA 클래스 사용해 피쳐 벡터화시킨 거 토픽모델링\n",
        "# n_components = 토픽개수\n",
        "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
        "lda.fit(ftr_vect)\n",
        "\n",
        "# 각 토픽\n",
        "print(lda.components_.shape)\n",
        "# 단어들을 벡터화한 feature\n",
        "print(lda.components_)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 doc\n",
            "0  새해 나들이 멀리 서울 공연 전시 세종 문화 회관 신년 음악회 서울시 제공 신년 음...\n",
            "1  상계 시가지 준공 주년 서울 김성수 상계동 철거 지역 사진 서울 시립 북 서울 미술...\n",
            "2  황금 띠해 달 서울시 곳곳 문화 예술 프로그램 성 위 사진 특정 사실 관련 서울 손...\n",
            "3  우리 사회 그늘 자본 권력 예술 게릴라 천후 독립 예술 창작 집단 리슨 투 더시티 ...\n",
            "4  아파트 그 공간 의미 우리나라 아파트 선호 나라 주택 해결 아파트 건설 우리 곳 아...\n",
            "5  새해 시내 문화 예술 황금 띠 해 희망 찬 새해 시간 멀리 서울 시내 공연장 미술관...\n",
            "6  서울시 문화 예술 프로그램 소개 서울시 향 예술의전당 세종 문화 회관 신년 음악회 ...\n",
            "7  새해 볼 문화 행사 서울시 공연 전시 준비 웍스 박지윤 새해 가족 서울 공연장 미술...\n",
            "(5, 390)\n",
            "[[ 2.19999462  2.19999606  0.20000004 ... 10.19999455  4.19999551\n",
            "   6.16115441]\n",
            " [ 0.20000215  0.20000157  0.20000097 ...  0.20000218  0.20000179\n",
            "   0.20000525]\n",
            " [ 0.20000039  0.20000029  2.19537725 ...  0.2000004   0.20000033\n",
            "   0.20000097]\n",
            " [ 0.2000007   0.20000051  0.20462077 ...  0.2000007   0.20000058\n",
            "   0.23883411]\n",
            " [ 0.20000215  0.20000157  0.20000097 ...  0.20000218  0.20000179\n",
            "   0.20000525]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpjYLxVRi0PK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd7910f-ae81-4fb2-d0a9-8e6df2ab543e"
      },
      "source": [
        "# lda_model = 벡터화시킨 텍스트 데이터를 fit까지만 적용한 모델\n",
        "def display_topic_words(lda_model, feature_names, num_top_words):\n",
        "    for topic_idx, topic in enumerate(lda_model.components_):\n",
        "        print('\\nTopic #', topic_idx+1)\n",
        "\n",
        "        # topic 별로 1000개의 features 중에서 높은 값 순으로 정렬 후 index 반환\n",
        "        #argsort = 디폴트가 오름차순 -> [::-1]로 내림차순으로 변경\n",
        "        topic_word_idx = topic.argsort()[::-1]\n",
        "        top_idx = topic_word_idx[:num_top_words]\n",
        "\n",
        "        # CountVectorizer 함수 할당시킨 객체에 get_feature_names()로 벡터화시킨 features\n",
        "        # 벡터화시킨 feature는 숫자-알파벳 순으로 정렬, 단어들 순서는 fit_transform 시키고 난 이후에도 동일\n",
        "        feature_concat = '+'.join([str(feature_names[i])+'*'+str(round(topic[i], 1)) for i in top_idx])\n",
        "        print(feature_concat)\n",
        "\n",
        "feature_names = count_vect.get_feature_names()\n",
        "display_topic_words(lda, feature_names, 5)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Topic # 1\n",
            "문화*76.2+예술*38.7+서울시*35.2+공간*30.2+프로그램*29.2\n",
            "\n",
            "Topic # 2\n",
            "관객*0.2+예술가*0.2+부부*0.2+창작*0.2+친구*0.2\n",
            "\n",
            "Topic # 3\n",
            "아파트*31.2+작가*12.2+주택*12.1+시가지*10.2+상계*10.1\n",
            "\n",
            "Topic # 4\n",
            "더시티*17.0+리슨*17.0+예술*10.7+작품*7.9+한국*6.1\n",
            "\n",
            "Topic # 5\n",
            "관객*0.2+예술가*0.2+부부*0.2+창작*0.2+친구*0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIuB-Pf1i4nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1badfe77-0c17-4cec-a83c-53664458108d"
      },
      "source": [
        "doc_topics = lda.transform(ftr_vect)\n",
        "print(doc_topics.shape)\n",
        "print(doc_topics)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 5)\n",
            "[[9.97171827e-01 7.04595053e-04 7.09844429e-04 7.09138450e-04\n",
            "  7.04595053e-04]\n",
            " [9.73971360e-04 9.66613309e-04 7.15351969e-01 2.81740833e-01\n",
            "  9.66613309e-04]\n",
            " [9.97720806e-01 5.66945336e-04 5.71807629e-04 5.73496030e-04\n",
            "  5.66945336e-04]\n",
            " [1.56979397e-01 1.47142293e-03 1.48502349e-03 8.38592734e-01\n",
            "  1.47142293e-03]\n",
            " [8.64321432e-04 8.58599150e-04 9.96546804e-01 8.71675842e-04\n",
            "  8.58599150e-04]\n",
            " [9.98536530e-01 3.63866082e-04 3.68220845e-04 3.67516580e-04\n",
            "  3.63866082e-04]\n",
            " [9.94725335e-01 1.31634070e-03 1.32090086e-03 1.32108278e-03\n",
            "  1.31634070e-03]\n",
            " [9.97399431e-01 6.47652158e-04 6.52894122e-04 6.52370986e-04\n",
            "  6.47652158e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlt8APlg_G9Q",
        "outputId": "38993ba4-241c-4bfe-ef27-7b7ce228e9dc"
      },
      "source": [
        "topic_names = ['Topic #' + str(i) for i in range(0,5)]\n",
        "topic_df = pd.DataFrame(data=doc_topics, columns=topic_names)\n",
        "print(topic_df)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Topic #0  Topic #1  Topic #2  Topic #3  Topic #4\n",
            "0  0.998493  0.000377  0.000375  0.000378  0.000377\n",
            "1  0.000655  0.000652  0.000652  0.997378  0.000664\n",
            "2  0.998888  0.000278  0.000277  0.000279  0.000278\n",
            "3  0.001248  0.001248  0.001242  0.001252  0.995010\n",
            "4  0.000619  0.142411  0.000614  0.855737  0.000620\n",
            "5  0.999234  0.000192  0.000190  0.000192  0.000192\n",
            "6  0.997309  0.000674  0.000671  0.000673  0.000673\n",
            "7  0.998617  0.000345  0.000344  0.000346  0.000347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySgx0GZPIlBb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}